{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 is available\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"{device} is available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Image Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image cnt : 100\n",
      "Image cnt : 100\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "PATH = 'Data/'\n",
    "HR_list = os.listdir(PATH + 'HR/')\n",
    "print(\"Image cnt : {}\".format(len(HR_list)))\n",
    "\n",
    "LR_list = os.listdir(PATH + 'LR/')\n",
    "print(\"Image cnt : {}\".format(len(LR_list)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.png', '1.png', '10.png', '11.png', '12.png', '13.png', '14.png', '15.png', '16.png', '17.png', '18.png', '19.png', '2.png', '20.png', '21.png', '22.png', '23.png', '24.png', '25.png', '26.png', '27.png', '28.png', '29.png', '3.png', '30.png', '31.png', '32.png', '33.png', '34.png', '35.png', '36.png', '37.png', '38.png', '39.png', '4.png', '40.png', '41.png', '42.png', '43.png', '44.png', '45.png', '46.png', '47.png', '48.png', '49.png', '5.png', '50.png', '51.png', '52.png', '53.png', '54.png', '55.png', '56.png', '57.png', '58.png', '59.png', '6.png', '60.png', '61.png', '62.png', '63.png', '64.png', '65.png', '66.png', '67.png', '68.png', '69.png', '7.png', '70.png', '71.png', '72.png', '73.png', '74.png', '75.png', '76.png', '77.png', '78.png', '79.png', '8.png', '80.png', '81.png', '82.png', '83.png', '84.png', '85.png', '86.png', '87.png', '88.png', '89.png', '9.png', '90.png', '91.png', '92.png', '93.png', '94.png', '95.png', '96.png', '97.png', '98.png', '99.png']\n"
     ]
    }
   ],
   "source": [
    "print(HR_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "LR_images = []\n",
    "for path in LR_list:\n",
    "    img = Image.open(os.path.join(PATH, 'LR', path))\n",
    "    img = np.asarray(img)\n",
    "    LR_images.append(img)\n",
    "\n",
    "HR_images = []\n",
    "for path in HR_list:\n",
    "    img = Image.open(os.path.join(PATH, 'HR', path))\n",
    "    img = np.asarray(img)\n",
    "    HR_images.append(img)\n",
    "\n",
    "LR_images = np.asarray(LR_images)\n",
    "HR_images = np.asarray(HR_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Images shape : (100, 96, 96, 3)\n",
      "HR Images shape : (100, 384, 384, 3)\n"
     ]
    }
   ],
   "source": [
    "print(f\"LR Images shape : {LR_images.shape}\")\n",
    "print(f\"HR Images shape : {HR_images.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create B ResidualBlock  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class B_ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1):\n",
    "        super(B_ResidualBlock, self).__init__()\n",
    "        \n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.Conv2d(self.in_channels, self.out_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(self.out_channels),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(self.out_channels),\n",
    "        )\n",
    "        if self.stride != 1 or self.in_channels != self.out_channels:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, self.out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.out_channels)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv_block(x)\n",
    "        if self.stride != 1 or self.in_channels != self.out_channels:\n",
    "            x = self.downsample(x)\n",
    "        out = x + out\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.num_bloacks = 5\n",
    "\n",
    "        self.base = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "\n",
    "        self.layer1 = self.make_layer(64, self.num_bloacks, stride=1)    # B_residual blocks\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64)\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 256, 3, padding=1),\n",
    "            nn.PixelShuffle(2),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(64, 256, 3, padding=1),\n",
    "            nn.PixelShuffle(2),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "        self.layer5 = nn.Conv2d(64, 3, 9, stride=1, padding=4)\n",
    "\n",
    "\n",
    "    def make_layer(self, out_channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "\n",
    "        for stride in strides:\n",
    "            block = B_ResidualBlock(self.in_channels, out_channels)\n",
    "            layers.append(block)\n",
    "            self.in_channels = out_channels\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        base = self.base(x)         # base : used for 'skip connection'\n",
    "        layer1 = self.layer1(base)  # layer1 : B_residual blocks\n",
    "        layer2 = self.layer2(layer1)\n",
    "        layer2 = layer2 + base      # Elementwise Sum\n",
    "        \n",
    "        layer3 = self.layer3(layer2)\n",
    "        layer4 = self.layer4(layer3)\n",
    "        layer5 = self.layer5(layer4)\n",
    "        return layer5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "generator = Generator().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 96, 96]           1,728\n",
      "             PReLU-2           [-1, 64, 96, 96]               1\n",
      "            Conv2d-3           [-1, 64, 96, 96]          36,864\n",
      "       BatchNorm2d-4           [-1, 64, 96, 96]             128\n",
      "             PReLU-5           [-1, 64, 96, 96]               1\n",
      "            Conv2d-6           [-1, 64, 96, 96]          36,864\n",
      "       BatchNorm2d-7           [-1, 64, 96, 96]             128\n",
      "   B_ResidualBlock-8           [-1, 64, 96, 96]               0\n",
      "            Conv2d-9           [-1, 64, 96, 96]          36,864\n",
      "      BatchNorm2d-10           [-1, 64, 96, 96]             128\n",
      "            PReLU-11           [-1, 64, 96, 96]               1\n",
      "           Conv2d-12           [-1, 64, 96, 96]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 96, 96]             128\n",
      "  B_ResidualBlock-14           [-1, 64, 96, 96]               0\n",
      "           Conv2d-15           [-1, 64, 96, 96]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 96, 96]             128\n",
      "            PReLU-17           [-1, 64, 96, 96]               1\n",
      "           Conv2d-18           [-1, 64, 96, 96]          36,864\n",
      "      BatchNorm2d-19           [-1, 64, 96, 96]             128\n",
      "  B_ResidualBlock-20           [-1, 64, 96, 96]               0\n",
      "           Conv2d-21           [-1, 64, 96, 96]          36,864\n",
      "      BatchNorm2d-22           [-1, 64, 96, 96]             128\n",
      "            PReLU-23           [-1, 64, 96, 96]               1\n",
      "           Conv2d-24           [-1, 64, 96, 96]          36,864\n",
      "      BatchNorm2d-25           [-1, 64, 96, 96]             128\n",
      "  B_ResidualBlock-26           [-1, 64, 96, 96]               0\n",
      "           Conv2d-27           [-1, 64, 96, 96]          36,864\n",
      "      BatchNorm2d-28           [-1, 64, 96, 96]             128\n",
      "            PReLU-29           [-1, 64, 96, 96]               1\n",
      "           Conv2d-30           [-1, 64, 96, 96]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 96, 96]             128\n",
      "  B_ResidualBlock-32           [-1, 64, 96, 96]               0\n",
      "           Conv2d-33           [-1, 64, 96, 96]          36,928\n",
      "      BatchNorm2d-34           [-1, 64, 96, 96]             128\n",
      "           Conv2d-35          [-1, 256, 96, 96]         147,712\n",
      "     PixelShuffle-36         [-1, 64, 192, 192]               0\n",
      "            PReLU-37         [-1, 64, 192, 192]               1\n",
      "           Conv2d-38        [-1, 256, 192, 192]         147,712\n",
      "     PixelShuffle-39         [-1, 64, 384, 384]               0\n",
      "            PReLU-40         [-1, 64, 384, 384]               1\n",
      "           Conv2d-41          [-1, 3, 384, 384]          15,555\n",
      "================================================================\n",
      "Total params: 719,691\n",
      "Trainable params: 719,691\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.11\n",
      "Forward/backward pass size (MB): 426.38\n",
      "Params size (MB): 2.75\n",
      "Estimated Total Size (MB): 429.23\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torchsummary\n",
    "torchsummary.summary(generator, (3, 96, 96))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.in_channels = 64\n",
    "\n",
    "        self.base = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, 1, padding=1),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        self.conv_layer1 = self.make_layer(64, 64, 2)\n",
    "        self.conv_layer2 = self.make_layer(64, 128, 1)\n",
    "        self.conv_layer3 = self.make_layer(128, 128, 2)\n",
    "        self.conv_layer4 = self.make_layer(128, 256, 1)\n",
    "        self.conv_layer5 = self.make_layer(256, 256, 2)\n",
    "        self.conv_layer6 = self.make_layer(256, 512, 1)\n",
    "        self.conv_layer7 = self.make_layer(512, 512, 2)\n",
    "\n",
    "        self.fc_layer1 = nn.Sequential(\n",
    "            nn.Linear(512 * 6 * 6, 1024, bias=False),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        self.fc_layer2 = nn.Sequential(\n",
    "            nn.Linear(1024, 1, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def make_layer(self, in_channels, out_channels, stride):\n",
    "        conv_block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        return conv_block\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.base(x)\n",
    "        out = self.conv_layer1(out)\n",
    "        out = self.conv_layer2(out)\n",
    "        out = self.conv_layer3(out)\n",
    "        out = self.conv_layer4(out)\n",
    "        out = self.conv_layer5(out)\n",
    "        out = self.conv_layer6(out)\n",
    "        out = self.conv_layer7(out)\n",
    "\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc_layer1(out)\n",
    "        out = self.fc_layer2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 96, 96]           1,792\n",
      "         LeakyReLU-2           [-1, 64, 96, 96]               0\n",
      "            Conv2d-3           [-1, 64, 48, 48]          36,864\n",
      "       BatchNorm2d-4           [-1, 64, 48, 48]             128\n",
      "         LeakyReLU-5           [-1, 64, 48, 48]               0\n",
      "            Conv2d-6          [-1, 128, 48, 48]          73,728\n",
      "       BatchNorm2d-7          [-1, 128, 48, 48]             256\n",
      "         LeakyReLU-8          [-1, 128, 48, 48]               0\n",
      "            Conv2d-9          [-1, 128, 24, 24]         147,456\n",
      "      BatchNorm2d-10          [-1, 128, 24, 24]             256\n",
      "        LeakyReLU-11          [-1, 128, 24, 24]               0\n",
      "           Conv2d-12          [-1, 256, 24, 24]         294,912\n",
      "      BatchNorm2d-13          [-1, 256, 24, 24]             512\n",
      "        LeakyReLU-14          [-1, 256, 24, 24]               0\n",
      "           Conv2d-15          [-1, 256, 12, 12]         589,824\n",
      "      BatchNorm2d-16          [-1, 256, 12, 12]             512\n",
      "        LeakyReLU-17          [-1, 256, 12, 12]               0\n",
      "           Conv2d-18          [-1, 512, 12, 12]       1,179,648\n",
      "      BatchNorm2d-19          [-1, 512, 12, 12]           1,024\n",
      "        LeakyReLU-20          [-1, 512, 12, 12]               0\n",
      "           Conv2d-21            [-1, 512, 6, 6]       2,359,296\n",
      "      BatchNorm2d-22            [-1, 512, 6, 6]           1,024\n",
      "        LeakyReLU-23            [-1, 512, 6, 6]               0\n",
      "           Linear-24                 [-1, 1024]      18,874,368\n",
      "        LeakyReLU-25                 [-1, 1024]               0\n",
      "           Linear-26                    [-1, 1]           1,024\n",
      "          Sigmoid-27                    [-1, 1]               0\n",
      "================================================================\n",
      "Total params: 23,562,624\n",
      "Trainable params: 23,562,624\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.11\n",
      "Forward/backward pass size (MB): 27.16\n",
      "Params size (MB): 89.88\n",
      "Estimated Total Size (MB): 117.15\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "discriminator = Discriminator().to(device)\n",
    "torchsummary.summary(discriminator, (3, 96, 96))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function / Content loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator Test\n",
    "- Input 데이터를 넣으면 SR 데이터로 업스케일링이 잘 되는지 확인해보장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Images shape : (100, 96, 96, 3)\n",
      "HR Images shape : (100, 384, 384, 3)\n"
     ]
    }
   ],
   "source": [
    "print(f\"LR Images shape : {LR_images.shape}\")\n",
    "print(f\"HR Images shape : {HR_images.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 96, 3)\n"
     ]
    }
   ],
   "source": [
    "print(LR_images[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_tensor = torch.Tensor(LR_images)\n",
    "HR_tensor = torch.Tensor(HR_images)\n",
    "\n",
    "LR_dataloader = DataLoader(LR_tensor)\n",
    "HR_dataloader = DataLoader(HR_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(LR_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for data in LR_dataloader:\n",
    "    inputs = data.to(device)\n",
    "    outputs = generator(inputs.view(-1, 3, 96, 96))\n",
    "    result.append(outputs)\n",
    "    break\n",
    "\n",
    "print(len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.asarray(result[0].cpu().detach().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 384, 384)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1c8aeb3d863020db46c0ab5cbeb479db59ccef6d66bc3ca241d1507778b1cad8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
